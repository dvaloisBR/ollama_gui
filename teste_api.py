#!/usr/bin/env python3
import requests
import subprocess
import time
import os

def run_command(cmd, timeout=10):
    """Executa um comando e retorna o resultado"""
    try:
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True, timeout=timeout)
        return {
            'success': result.returncode == 0,
            'stdout': result.stdout.strip(),
            'stderr': result.stderr.strip(),
            'returncode': result.returncode
        }
    except subprocess.TimeoutExpired:
        return {'success': False, 'error': 'Timeout'}
    except Exception as e:
        return {'success': False, 'error': str(e)}

def diagnosticar_ollama():
    print("ğŸ©º DIAGNÃ“STICO COMPLETO DO OLLAMA")
    print("=" * 50)
    
    # 1. Verifica se o Ollama estÃ¡ instalado
    print("1. ğŸ“¦ Verificando instalaÃ§Ã£o do Ollama...")
    result = run_command("which ollama")
    if result['success']:
        print("   âœ… Ollama encontrado:", result['stdout'])
    else:
        print("   âŒ Ollama nÃ£o encontrado no PATH")
        print("   ğŸ’¡ Instale com: curl -fsSL https://ollama.ai/install.sh | sh")
        return False
    
    # 2. Verifica versÃ£o
    print("2. ğŸ” Verificando versÃ£o...")
    result = run_command("ollama --version")
    if result['success']:
        print("   âœ… VersÃ£o:", result['stdout'])
    else:
        print("   âŒ NÃ£o foi possÃ­vel obter versÃ£o")
    
    # 3. Verifica processo
    print("3. ğŸ”„ Verificando processos...")
    result = run_command("pgrep -f ollama")
    if result['success'] and result['stdout']:
        print("   âœ… Processos Ollama encontrados:", result['stdout'])
    else:
        print("   âŒ Nenhum processo Ollama encontrado")
        print("   ğŸ’¡ Execute: ollama serve")
    
    # 4. Verifica porta
    print("4. ğŸ”Œ Verificando porta 11434...")
    result = run_command("netstat -tuln | grep 11434 || ss -tuln | grep 11434")
    if result['success'] and '11434' in result['stdout']:
        print("   âœ… Porta 11434 estÃ¡ escutando")
    else:
        print("   âŒ Porta 11434 nÃ£o estÃ¡ escutando")
    
    # 5. Testa API
    print("5. ğŸŒ Testando API...")
    try:
        response = requests.get('http://localhost:11434/api/tags', timeout=5)
        if response.status_code == 200:
            data = response.json()
            models = data.get('models', [])
            print(f"   âœ… API respondendo - {len(models)} modelos")
            for model in models:
                print(f"      - {model['name']}")
        else:
            print(f"   âŒ API retornou status {response.status_code}")
    except Exception as e:
        print(f"   âŒ Erro na API: {e}")
    
    # 6. Lista modelos via comando
    print("6. ğŸ“‹ Listando modelos via comando...")
    result = run_command("ollama list", timeout=15)
    if result['success']:
        print("   âœ… Comando 'ollama list' executado:")
        print(result['stdout'])
    else:
        print("   âŒ Erro no comando 'ollama list':", result.get('stderr', result.get('error', 'Unknown')))
    
    # 7. Verifica permissÃµes
    print("7. ğŸ”’ Verificando permissÃµes...")
    ollama_dir = os.path.expanduser("~/.ollama")
    if os.path.exists(ollama_dir):
        print(f"   âœ… DiretÃ³rio Ollama existe: {ollama_dir}")
        stat = os.stat(ollama_dir)
        print(f"   ğŸ‘¤ Dono: {stat.st_uid}, PermissÃµes: {oct(stat.st_mode)[-3:]}")
    else:
        print(f"   âŒ DiretÃ³rio Ollama nÃ£o existe: {ollama_dir}")
    
    print("=" * 50)
    print("ğŸ¯ PRÃ“XIMOS PASSOS:")
    print("1. Se Ollama nÃ£o estÃ¡ rodando: ollama serve")
    print("2. Se nÃ£o hÃ¡ modelos: ollama pull llama3:8b-instruct-q4_K_M") 
    print("3. Se hÃ¡ erro de permissÃ£o: sudo chown -R $USER ~/.ollama")
    print("4. Reinicie o servidor Flask apÃ³s corrigir problemas")

if __name__ == '__main__':
    diagnosticar_ollama()